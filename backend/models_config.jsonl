{"model_key": "blip", "model_id": "Salesforce/blip-image-captioning-base", "type": "hf_vlm", "processor_class": "BlipProcessor", "model_class": "BlipForConditionalGeneration", "category": "general", "description": "Fast, basic image captioning", "vlm_capable": true, "supports_prompts": true, "supports_batch": true, "default_precision": "float32", "supported_precisions": ["float32"], "processor_config": {"use_fast": true}}
{"model_key": "blip2", "model_id": "Salesforce/blip2-opt-2.7b", "type": "hf_vlm", "processor_class": "Blip2Processor", "model_class": "Blip2ForConditionalGeneration", "category": "general", "description": "BLIP2-OPT-2.7B - Enhanced captioning", "vlm_capable": true, "supports_prompts": true, "supports_batch": true, "default_precision": "bfloat16", "supported_precisions": ["float32", "bfloat16"], "processor_config": {"use_fast": true}}
{"model_key": "r4b", "model_id": "YannQi/R-4B", "type": "hf_vlm", "processor_class": "AutoProcessor", "model_class": "AutoModel", "category": "general", "description": "Advanced reasoning model with configurable parameters", "vlm_capable": true, "supports_prompts": true, "supports_batch": true, "default_precision": "float32", "supported_precisions": ["float32", "4bit", "8bit"], "special_params": ["thinking_mode"], "processor_config": {"trust_remote_code": true, "use_fast": false}, "model_config": {"trust_remote_code": true}, "postprocess": "extract_thinking_tags"}
{"model_key": "wdvit", "model_id": "SmilingWolf/wd-vit-large-tagger-v3", "type": "hf_tagger", "processor_class": "AutoImageProcessor", "model_class": "AutoModelForImageClassification", "category": "anime", "description": "WD-ViT Large Tagger v3 - Anime-style image tagging model with ViT backbone", "vlm_capable": false, "supports_prompts": false, "supports_batch": true, "default_precision": "float32", "requires_tags_csv": true}
{"model_key": "wdeva02", "model_id": "SmilingWolf/wd-eva02-large-tagger-v3", "type": "hf_tagger", "processor_class": "AutoImageProcessor", "model_class": "AutoModelForImageClassification", "category": "anime", "description": "WD-EVA02 Large Tagger v3 - Anime-style image tagging model with EVA02 backbone (improved accuracy)", "vlm_capable": false, "supports_prompts": false, "supports_batch": true, "default_precision": "float32", "requires_tags_csv": true}
{"model_key": "wd14-convnext", "model_id": "SmilingWolf/wd-v1-4-convnext-tagger-v2", "type": "onnx_tagger", "category": "anime", "description": "WD v1.4 ConvNext Tagger v2 - Fast ONNX-based anime tagging (optimized inference)", "vlm_capable": false, "supports_prompts": false, "supports_batch": true, "image_size": 448, "requires_tags_csv": true, "input_tensor_name": "input_1:0"}
{"model_key": "janus-1.3b", "model_id": "deepseek-ai/Janus-1.3B", "type": "hf_vlm_custom", "processor_class": "VLChatProcessor", "model_class": "AutoModelForCausalLM", "category": "multimodal", "description": "Janus 1.3B - Multimodal vision-language model with efficient architecture", "vlm_capable": true, "supports_prompts": true, "supports_batch": true, "default_precision": "bfloat16", "processor_config": {"trust_remote_code": true}, "model_config": {"trust_remote_code": true}, "custom_handler": "janus"}
{"model_key": "janus-pro-1b", "model_id": "deepseek-ai/Janus-Pro-1B", "type": "hf_vlm_custom", "processor_class": "VLChatProcessor", "model_class": "AutoModelForCausalLM", "category": "multimodal", "description": "Janus Pro 1B - Compact professional-grade vision model", "vlm_capable": true, "supports_prompts": true, "supports_batch": true, "default_precision": "bfloat16", "processor_config": {"trust_remote_code": true}, "model_config": {"trust_remote_code": true}, "custom_handler": "janus"}
{"model_key": "janus-pro-7b", "model_id": "deepseek-ai/Janus-Pro-7B", "type": "hf_vlm_custom", "processor_class": "VLChatProcessor", "model_class": "AutoModelForCausalLM", "category": "multimodal", "description": "Janus Pro 7B - Advanced multimodal model with superior reasoning capabilities", "vlm_capable": true, "supports_prompts": true, "supports_batch": true, "default_precision": "bfloat16", "processor_config": {"trust_remote_code": true}, "model_config": {"trust_remote_code": true}, "custom_handler": "janus"}
{"model_key": "lfm2-vl-3b", "model_id": "LiquidAI/LFM2-VL-3B", "type": "hf_vlm", "processor_class": "AutoProcessor", "model_class": "AutoModelForImageTextToText", "category": "multimodal", "description": "LFM2-VL-3B - LiquidAI's vision-language model with chat capabilities", "vlm_capable": true, "supports_prompts": true, "supports_batch": true, "default_precision": "bfloat16"}
{"model_key": "nanonets-ocr-s", "model_id": "nanonets/Nanonets-OCR-s", "type": "hf_ocr", "processor_class": "AutoProcessor", "model_class": "AutoModelForImageTextToText", "category": "ocr", "description": "Nanonets OCR-S - Lightweight OCR (tables/equations/HTML) via Transformers", "vlm_capable": false, "supports_prompts": false, "supports_batch": true, "default_precision": "bfloat16", "processor_config": {"trust_remote_code": true}, "model_config": {"trust_remote_code": true}}
{"model_key": "chandra-ocr", "model_id": "datalab-to/chandra", "type": "hf_ocr", "processor_class": "AutoProcessor", "model_class": "AutoModelForImageTextToText", "category": "ocr", "description": "Chandra OCR - Advanced layout-aware text extraction with table/equation support", "vlm_capable": false, "supports_prompts": false, "supports_batch": true, "default_precision": "bfloat16", "special_params": ["chandra_preset"], "processor_config": {"trust_remote_code": true}, "model_config": {"trust_remote_code": true}}
{"model_key": "trocr-large-printed", "model_id": "microsoft/trocr-large-printed", "type": "hf_ocr_trocr", "processor_class": "TrOCRProcessor", "model_class": "VisionEncoderDecoderModel", "category": "ocr", "description": "TrOCR Large Printed - Microsoft's transformer-based OCR for printed text", "vlm_capable": false, "supports_prompts": false, "supports_batch": true, "default_precision": "float32", "special_params": ["line_separator", "sort_boxes", "line_threshold"], "requires_text_detection": true}
{"model_key": "llava-phi3", "model_id": "xtuner/llava-phi-3-mini-hf", "type": "hf_vlm", "processor_class": "AutoProcessor", "model_class": "LlavaForConditionalGeneration", "category": "multimodal", "description": "LLaVA-Phi-3-Mini - Compact and efficient vision-language model", "vlm_capable": true, "supports_prompts": true, "supports_batch": true, "default_precision": "float16", "processor_config": {"trust_remote_code": true}}
{"model_key": "vit-classifier", "model_id": "google/vit-base-patch16-224", "type": "hf_classifier", "processor_class": "AutoProcessor", "model_class": "AutoModelForImageClassification", "category": "classification", "description": "Google ViT Base - ImageNet classification model (1000 object classes)", "vlm_capable": false, "supports_prompts": false, "supports_batch": true, "default_precision": "float32"}
