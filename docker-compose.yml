# AI Image Captioner - Docker Compose Configuration
# 
# Version numbers come from version.json
# Current config: python312-cuda128 (Python 3.12, CUDA 12.8, PyTorch 2.8.0)
#
# To use a different configuration:
# 1. Check available configs: jq '.build_configs | keys' version.json
# 2. Update the build args below with values from your chosen config
# 3. Run: docker-compose build

services:
  ai-image-captioner:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        # Value@s from version.json -> build_configs.python312-cuda128
        CUDA_BASE_VERSION: "12.8.0"        # .docker.cuda_base_version
        CUDNN_SUFFIX: "cudnn"              # .docker.cudnn_suffix
        CUDA_VERSION: "cu128"              # .cuda
        PYTHON_VERSION: "3.12"             # .python
        PYTORCH_VERSION: "2.8.0"           # .pytorch.version
        TORCHVISION_VERSION: "0.23.0"      # .pytorch.torchvision
        TORCHAUDIO_VERSION: "2.8.0"        # .pytorch.torchaudio
        PYTORCH_INDEX_URL: "https://download.pytorch.org/whl/cu128"  # .pytorch.index_url
        # FlashAttention configuration
        FLASH_ATTENTION_VERSION: "2.8.3"   # .flash_attention.version
        FLASH_ATTENTION_CUDA_SUFFIX: "cu12torch2.8cxx11abiTRUE"  # .flash_attention.cuda_suffix
        # Additional packages
        BUILD_HELPERS: "packaging,ninja"   # .additional_packages.build_helpers (comma-separated)
        DOCTR_PACKAGE: "python-doctr"  # .additional_packages.doctr
        # GPU-specific packages (installed only for GPU builds)
        GPU_SPECIFIC_PACKAGES: "bitsandbytes>=0.41.0,onnxruntime-gpu"  # .gpu_specific_packages (comma-separated)
    image: ai-image-captioner:latest
    container_name: ai-image-captioner

    # GPU support - requires nvidia-docker
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

    # Ports
    ports:
      - "5000:5000"

    # Volumes
    volumes:
      # Persist user config
      - ./user_config.json:/app/user_config.json
      # Persist database files (REQUIRED - stores image metadata and captions)
      - ai-image-captioner-data:/app/backend/data
      # Persist thumbnails (optional - avoids regenerating on restart)
      - ai-image-captioner-thumbnails:/app/backend/thumbnails
      # Cache Hugging Face models (optional - speeds up restarts)
      - huggingface-cache:/root/.cache/huggingface
      # Mount frontend for live editing (development only)
      # - ./frontend:/app/frontend

    # Environment variables
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - DEBUG_MODE=False
      # HuggingFace logging - shows model download/loading progress
      - TRANSFORMERS_VERBOSITY=info
      - HF_HUB_VERBOSITY=info

    # Restart policy
    restart: unless-stopped

    # Health check
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

volumes:
  huggingface-cache:
    driver: local
  ai-image-captioner-data:
    driver: local
  ai-image-captioner-thumbnails:
    driver: local
