# AI Image Captioner - Docker Compose Configuration
# 
# Version numbers come from version.json
# Current config: python312-cuda128 (Python 3.12, CUDA 12.8, PyTorch 2.8.0)
#
# To use a different configuration:
# 1. Check available configs: jq '.build_configs | keys' version.json
# 2. Update the build args below with values from your chosen config
# 3. Run: docker-compose build

services:
  ai-image-captioner:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        # Values from version.json -> build_configs.python312-cuda128
        CUDA_BASE_VERSION: "12.8.0"        # .docker.cuda_base_version
        CUDNN_SUFFIX: "cudnn"              # .docker.cudnn_suffix
        CUDA_VERSION: "cu128"              # .cuda
        PYTHON_VERSION: "3.12"             # .python
        PYTORCH_VERSION: "2.8.0"           # .pytorch.version
        PYTORCH_INDEX_URL: "https://download.pytorch.org/whl/cu128"  # .pytorch.index_url
    image: ai-image-captioner:latest
    container_name: ai-image-captioner

    # GPU support - requires nvidia-docker
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

    # Ports
    ports:
      - "5000:5000"

    # Volumes
    volumes:
      # Persist user config
      - ./user_config.json:/app/user_config.json
      # Cache Hugging Face models (optional - speeds up restarts)
      - huggingface-cache:/root/.cache/huggingface
      # Mount frontend for live editing (development only)
      # - ./frontend:/app/frontend

    # Environment variables
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - DEBUG_MODE=False

    # Restart policy
    restart: unless-stopped

    # Health check
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

volumes:
  huggingface-cache:
    driver: local
