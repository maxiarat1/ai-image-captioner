name: Release

on:
  push:
    tags:
      - 'v*.*.*'
  workflow_dispatch:
    inputs:
      version:
        description: 'Version (e.g., v1.0.0)'
        required: true
        type: string

jobs:
  # Read version configuration and prepare matrix
  setup:
    runs-on: ubuntu-latest
    outputs:
      release_version: ${{ steps.version.outputs.release_version }}
      configs: ${{ steps.configs.outputs.matrix }}
    steps:
      - uses: actions/checkout@v4

      - name: Get release version
        id: version
        run: |
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            echo "release_version=${{ github.event.inputs.version }}" >> $GITHUB_OUTPUT
          else
            echo "release_version=${GITHUB_REF#refs/tags/}" >> $GITHUB_OUTPUT
          fi

      - name: Generate build matrix from version.json
        id: configs
        run: |
          CONFIGS=$(jq -c '[.build_configs | to_entries[] | {
            name: .key,
            python: .value.python,
            cuda: .value.cuda,
            cuda_display: .value.cuda_version_display,
            pytorch: .value.pytorch
          }]' version.json)
          echo "matrix=${CONFIGS}" >> $GITHUB_OUTPUT
          echo "Building configs:"
          echo "$CONFIGS" | jq -r '.[] | "  - \(.name): Python \(.python), CUDA \(.cuda_display)"'

  # Build executables for all configs and platforms
  build-executables:
    needs: setup
    strategy:
      fail-fast: false
      max-parallel: 2
      matrix:
        os: [ubuntu-latest, windows-latest]
        config: ${{ fromJson(needs.setup.outputs.configs) }}

    runs-on: ${{ matrix.os }}

    steps:
      - uses: actions/checkout@v4

      - name: Free up disk space (Linux)
        if: runner.os == 'Linux'
        run: |
          echo "Disk space before cleanup:"
          df -h
          sudo rm -rf /usr/share/dotnet /opt/ghc /usr/local/share/boost "$AGENT_TOOLSDIRECTORY" \
                      /usr/local/lib/android /usr/share/swift /opt/hostedtoolcache
          sudo docker system prune -af || true
          echo "Disk space after cleanup:"
          df -h

      - name: Free up disk space (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          Write-Host "Disk space before cleanup:"
          Get-PSDrive
          Remove-Item -Path "C:\hostedtoolcache" -Recurse -Force -ErrorAction SilentlyContinue
          Remove-Item -Path "C:\Program Files\dotnet" -Recurse -Force -ErrorAction SilentlyContinue
          Write-Host "Disk space after cleanup:"
          Get-PSDrive

      - name: Set platform name
        id: platform
        shell: bash
        run: |
          if [ "${{ matrix.os }}" == "ubuntu-latest" ]; then
            echo "name=linux" >> $GITHUB_OUTPUT
          else
            echo "name=windows" >> $GITHUB_OUTPUT
          fi

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.config.python }}

      - name: Install PyTorch and dependencies
        shell: bash
        run: |
          python -m pip install --upgrade pip

          CONFIG_NAME="${{ matrix.config.name }}"

          # Read PyTorch config from version.json at runtime
          PYTORCH_VERSION=$(jq -r --arg cfg "$CONFIG_NAME" '.build_configs[$cfg].pytorch.version' version.json)
          TORCHVISION=$(jq -r --arg cfg "$CONFIG_NAME" '.build_configs[$cfg].pytorch.torchvision' version.json)
          TORCHAUDIO=$(jq -r --arg cfg "$CONFIG_NAME" '.build_configs[$cfg].pytorch.torchaudio' version.json)
          INDEX_URL=$(jq -r --arg cfg "$CONFIG_NAME" '.build_configs[$cfg].pytorch.index_url' version.json)
          CUDA_LABEL=$(jq -r --arg cfg "$CONFIG_NAME" '.build_configs[$cfg].cuda' version.json)

          # Read additional packages config
          DOCTR_PACKAGE=$(jq -r --arg cfg "$CONFIG_NAME" '.build_configs[$cfg].additional_packages.doctr' version.json)

          echo "Installing PyTorch ${PYTORCH_VERSION} with CUDA ${CUDA_LABEL}"

          pip install torch==${PYTORCH_VERSION}+${CUDA_LABEL} \
                      torchvision==${TORCHVISION}+${CUDA_LABEL} \
                      torchaudio==${TORCHAUDIO}+${CUDA_LABEL} \
                      --index-url "$INDEX_URL"

          # Install additional packages before requirements.txt
          if [ "$DOCTR_PACKAGE" != "null" ] && [ -n "$DOCTR_PACKAGE" ]; then
            echo "Installing doctr: $DOCTR_PACKAGE"
            pip install "$DOCTR_PACKAGE"
          fi

          pip install -r requirements.txt

          # Install GPU-specific packages (bitsandbytes, onnxruntime-gpu, etc.)
          GPU_PACKAGES=$(jq -r --arg cfg "$CONFIG_NAME" '.build_configs[$cfg].gpu_specific_packages[]?' version.json)
          if [ -n "$GPU_PACKAGES" ]; then
            echo "Installing GPU-specific packages:"
            echo "$GPU_PACKAGES" | while read -r pkg; do
              if [ -n "$pkg" ]; then
                echo "  - $pkg"
                pip install "$pkg"
              fi
            done
          fi

          pip install pyinstaller

      - name: Build executable
        shell: bash
        run: |
          cd backend
          pyinstaller captioner.spec --distpath ../dist --workpath ../build
          cd ..
          rm -rf build/
          pip cache purge || true

      - name: Package artifacts
        shell: bash
        run: |
          PLATFORM="${{ steps.platform.outputs.name }}"
          CONFIG="${{ matrix.config.name }}"
          BASE_NAME="ai-image-captioner-${PLATFORM}-${CONFIG}"
          mkdir -p artifacts
          
          if [ "$PLATFORM" == "windows" ]; then
            # Windows: use 7z for splitting (always split for consistency)
            7z a -tzip -v2000m "${BASE_NAME}.zip" ./dist/ai-image-captioner
            mv ${BASE_NAME}.zip* artifacts/
          else
            # Linux: check size and split if needed
            SIZE=$(du -sb dist/ai-image-captioner | cut -f1)
            if [ $SIZE -gt 2000000000 ]; then
              tar -czf - -C dist ai-image-captioner | split -b 2000m - "artifacts/${BASE_NAME}.tar.gz.part"
            else
              tar -czf "artifacts/${BASE_NAME}.tar.gz" -C dist ai-image-captioner
            fi
          fi
          
          rm -rf dist/

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: ${{ steps.platform.outputs.name }}-${{ matrix.config.name }}
          path: artifacts/
          retention-days: 5

  # Build Docker images for all configs
  build-docker:
    needs: setup
    strategy:
      fail-fast: false
      matrix:
        config: ${{ fromJson(needs.setup.outputs.configs) }}

    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write

    steps:
      - uses: actions/checkout@v4

      - name: Free up disk space
        run: |
          echo "Disk space before cleanup:"
          df -h
          sudo rm -rf /usr/share/dotnet /opt/ghc /usr/local/share/boost "$AGENT_TOOLSDIRECTORY" \
                      /usr/local/lib/android /usr/share/swift /opt/hostedtoolcache
          sudo docker system prune -af || true
          echo "Disk space after cleanup:"
          df -h

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Read CUDA base config from version.json
        id: docker_config
        run: |
          CONFIG_NAME="${{ matrix.config.name }}"
          
          # Extract Docker build args from version.json
          CUDA_BASE=$(jq -r --arg cfg "$CONFIG_NAME" \
            '.build_configs[$cfg].docker.cuda_base_version' version.json)
          CUDNN_SUFFIX=$(jq -r --arg cfg "$CONFIG_NAME" \
            '.build_configs[$cfg].docker.cudnn_suffix' version.json)
          PYTORCH_VERSION=$(jq -r --arg cfg "$CONFIG_NAME" \
            '.build_configs[$cfg].pytorch.version' version.json)
          TORCHVISION_VERSION=$(jq -r --arg cfg "$CONFIG_NAME" \
            '.build_configs[$cfg].pytorch.torchvision' version.json)
          TORCHAUDIO_VERSION=$(jq -r --arg cfg "$CONFIG_NAME" \
            '.build_configs[$cfg].pytorch.torchaudio' version.json)
          PYTORCH_INDEX=$(jq -r --arg cfg "$CONFIG_NAME" \
            '.build_configs[$cfg].pytorch.index_url' version.json)
          
          # Extract FlashAttention config
          FA_VERSION=$(jq -r --arg cfg "$CONFIG_NAME" \
            '.build_configs[$cfg].flash_attention.version' version.json)
          FA_CUDA_SUFFIX=$(jq -r --arg cfg "$CONFIG_NAME" \
            '.build_configs[$cfg].flash_attention.cuda_suffix' version.json)
          
          # Extract additional packages
          BUILD_HELPERS=$(jq -r --arg cfg "$CONFIG_NAME" \
            '.build_configs[$cfg].additional_packages.build_helpers | join(",")' version.json)
          DOCTR_PACKAGE=$(jq -r --arg cfg "$CONFIG_NAME" \
            '.build_configs[$cfg].additional_packages.doctr' version.json)
          ONNXRUNTIME_PACKAGE=$(jq -r --arg cfg "$CONFIG_NAME" \
            '.build_configs[$cfg].additional_packages.onnxruntime' version.json)
          
          if [ "$CUDA_BASE" == "null" ] || [ "$CUDNN_SUFFIX" == "null" ]; then
            echo "Error: Docker config missing in version.json for $CONFIG_NAME"
            exit 1
          fi
          
          echo "cuda_base=$CUDA_BASE" >> $GITHUB_OUTPUT
          echo "cudnn_suffix=$CUDNN_SUFFIX" >> $GITHUB_OUTPUT
          echo "pytorch_version=$PYTORCH_VERSION" >> $GITHUB_OUTPUT
          echo "torchvision_version=$TORCHVISION_VERSION" >> $GITHUB_OUTPUT
          echo "torchaudio_version=$TORCHAUDIO_VERSION" >> $GITHUB_OUTPUT
          echo "pytorch_index=$PYTORCH_INDEX" >> $GITHUB_OUTPUT
          echo "fa_version=$FA_VERSION" >> $GITHUB_OUTPUT
          echo "fa_cuda_suffix=$FA_CUDA_SUFFIX" >> $GITHUB_OUTPUT
          echo "build_helpers=$BUILD_HELPERS" >> $GITHUB_OUTPUT
          echo "doctr_package=$DOCTR_PACKAGE" >> $GITHUB_OUTPUT
          echo "onnxruntime_package=$ONNXRUNTIME_PACKAGE" >> $GITHUB_OUTPUT
          echo "Using CUDA base: $CUDA_BASE, cuDNN suffix: $CUDNN_SUFFIX, PyTorch: $PYTORCH_VERSION, FlashAttention: $FA_VERSION"

      - name: Extract metadata for Docker
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ghcr.io/${{ github.repository }}
          tags: |
            type=raw,value=${{ needs.setup.outputs.release_version }}-${{ matrix.config.name }}
            type=raw,value=latest-${{ matrix.config.name }}

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          build-args: |
            PYTHON_VERSION=${{ matrix.config.python }}
            CUDA_VERSION=${{ matrix.config.cuda }}
            CUDA_BASE_VERSION=${{ steps.docker_config.outputs.cuda_base }}
            CUDNN_SUFFIX=${{ steps.docker_config.outputs.cudnn_suffix }}
            PYTORCH_VERSION=${{ steps.docker_config.outputs.pytorch_version }}
            TORCHVISION_VERSION=${{ steps.docker_config.outputs.torchvision_version }}
            TORCHAUDIO_VERSION=${{ steps.docker_config.outputs.torchaudio_version }}
            PYTORCH_INDEX_URL=${{ steps.docker_config.outputs.pytorch_index }}
            FLASH_ATTENTION_VERSION=${{ steps.docker_config.outputs.fa_version }}
            FLASH_ATTENTION_CUDA_SUFFIX=${{ steps.docker_config.outputs.fa_cuda_suffix }}
            BUILD_HELPERS=${{ steps.docker_config.outputs.build_helpers }}
            DOCTR_PACKAGE=${{ steps.docker_config.outputs.doctr_package }}
            ONNXRUNTIME_PACKAGE=${{ steps.docker_config.outputs.onnxruntime_package }}
          cache-from: type=gha,scope=${{ matrix.config.name }}
          cache-to: type=gha,mode=max,scope=${{ matrix.config.name }}
          platforms: linux/amd64

  # Create GitHub release with all artifacts
  create-release:
    needs: [setup, build-executables, build-docker]
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - uses: actions/checkout@v4

      - name: Free up disk space
        run: |
          sudo rm -rf /usr/share/dotnet /opt/ghc /usr/local/share/boost \
                      /usr/local/lib/android /usr/share/swift /opt/hostedtoolcache
          sudo docker system prune -af || true

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts

      - name: Prepare release artifacts
        run: |
          mkdir -p release-files
          find artifacts -type f \( -name "*.zip*" -o -name "*.tar.gz*" -o -name "*.part*" \) -exec cp {} release-files/ \;
          rm -rf artifacts/
          echo "Release files:"
          ls -lh release-files/

      - name: Generate release notes
        run: |
          VERSION="${{ needs.setup.outputs.release_version }}"
          REPO="${{ github.repository }}"

          # Get first config (for Docker example)
          FIRST_CONFIG=$(jq -r '.build_configs | to_entries[0] | .key' version.json)

          cat > release-notes.md << EOF
          ## AI Image Captioner ${VERSION}

          ### Quick Start

          ---

          ### **Option 1: Docker (Recommended)**

          **Recommended:** Full setup with persistent volumes

          \`\`\`bash
          docker run --gpus all -p 5000:5000 \
            -v ai-captioner-data:/app/backend/data \
            -v ai-captioner-thumbnails:/app/backend/thumbnails \
            -v huggingface-cache:/root/.cache/huggingface \
            ghcr.io/${REPO}:${VERSION}-${FIRST_CONFIG}
          \`\`\`

          \`\`\`bash
          docker start -a ai-captioner
          \`\`\`

          #### What each volume does:

          1. **ai-captioner-data:/app/backend/data** — **Required**

            - Stores all database files (image metadata, captions, sessions)
            - Without this, all data is lost on restart

          2. **huggingface-cache:/root/.cache/huggingface** — **Highly recommended**

            - Caches downloaded AI models
            - Without this, models re-download every time the container restarts

          3. **ai-captioner-thumbnails:/app/backend/thumbnails** — Optional

            - Stores generated thumbnails
            - Improves UI loading performance

          ---

          ### **Option 2: Executable**

          Extract and run the appropriate build:

          EOF

          # Add build config links
          jq -r '.build_configs | to_entries[] |
            "- **\(.key)** (Python \(.value.python), CUDA \(.value.cuda_version_display)): \(.value.description)"' \
            version.json >> release-notes.md

          cat >> release-notes.md << 'EOF'

          **Windows:**
          ```powershell
          # If you have split archives (.zip.001, .zip.002, etc.), combine them first:
          # Using 7-Zip: Right-click the .zip.001 file → 7-Zip → Extract Here

          # Then extract and run:
          ai-image-captioner.exe
          ```

          **Linux:**
          ```bash
          # If you have split archives (.tar.gz.partaa, .tar.gz.partab, etc.), combine them first:
          cat ai-image-captioner-linux-*.tar.gz.part* > ai-image-captioner-linux.tar.gz
          tar -xzf ai-image-captioner-linux.tar.gz

          # Or if you have a single archive:
          tar -xzf ai-image-captioner-linux-*.tar.gz

          # Then run:
          ./ai-image-captioner/ai-image-captioner
          ```

          ---

          ### **Frontend UI**

          Clone the repository and open `frontend/index.html` in your browser.

          ---

          AI models will automatically download on first run from the Hugging Face Hub.
          EOF

      - name: Create Release
        uses: softprops/action-gh-release@v2
        with:
          tag_name: ${{ needs.setup.outputs.release_version }}
          name: Release ${{ needs.setup.outputs.release_version }}
          body_path: release-notes.md
          draft: false
          files: release-files/*
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
