name: Release

on:
  push:
    tags:
      - 'v*.*.*'
  workflow_dispatch:
    inputs:
      version:
        description: 'Version (e.g., v1.0.0)'
        required: true
        type: string

jobs:
  # Read version configuration and prepare matrix
  setup:
    runs-on: ubuntu-latest
    outputs:
      release_version: ${{ steps.version.outputs.release_version }}
      configs: ${{ steps.configs.outputs.matrix }}
    steps:
      - uses: actions/checkout@v4

      - name: Get release version
        id: version
        run: |
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            echo "release_version=${{ github.event.inputs.version }}" >> $GITHUB_OUTPUT
          else
            echo "release_version=${GITHUB_REF#refs/tags/}" >> $GITHUB_OUTPUT
          fi

      - name: Generate build matrix from version.json
        id: configs
        run: |
          # Extract all build configs and create matrix
          CONFIGS=$(jq -c '[.build_configs | to_entries[] | {
            name: .key,
            python: .value.python,
            cuda: .value.cuda,
            cuda_display: .value.cuda_version_display
          }]' version.json)
          echo "matrix=${CONFIGS}" >> $GITHUB_OUTPUT
          echo "Building configs:"
          echo "$CONFIGS" | jq -r '.[] | "  - \(.name): Python \(.python), CUDA \(.cuda_display)"'

  # Build executables for all configs and platforms
  build-executables:
    needs: setup
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest]
        config: ${{ fromJson(needs.setup.outputs.configs) }}

    runs-on: ${{ matrix.os }}

    steps:
      - uses: actions/checkout@v4

      - name: Set platform name
        id: platform
        shell: bash
        run: |
          if [ "${{ matrix.os }}" == "ubuntu-latest" ]; then
            echo "name=linux" >> $GITHUB_OUTPUT
            echo "ext=tar.gz" >> $GITHUB_OUTPUT
          else
            echo "name=windows" >> $GITHUB_OUTPUT
            echo "ext=zip" >> $GITHUB_OUTPUT
          fi

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.config.python }}

      - name: Install dependencies
        shell: bash
        run: |
          python -m pip install --upgrade pip
          pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/${{ matrix.config.cuda }}
          pip install -r requirements.txt
          pip install pyinstaller

      - name: Build executable
        shell: bash
        run: |
          cd backend
          pyinstaller tagger.spec --distpath ../dist --workpath ../build

      - name: Package (Windows)
        if: steps.platform.outputs.name == 'windows'
        shell: bash
        run: |
          BASE_NAME="ai-image-tagger-${{ steps.platform.outputs.name }}-${{ matrix.config.name }}"
          mkdir -p artifacts
          # Create split archives if size > 2GB, otherwise single archive
          7z a -tzip -v2000m "${BASE_NAME}.zip" ./dist/ai-image-tagger
          # Move all parts to artifacts folder
          mv ${BASE_NAME}.zip* artifacts/

      - name: Package (Linux)
        if: steps.platform.outputs.name == 'linux'
        run: |
          BASE_NAME="ai-image-tagger-${{ steps.platform.outputs.name }}-${{ matrix.config.name }}"
          mkdir -p artifacts
          # Check size first
          SIZE=$(du -sb dist/ai-image-tagger | cut -f1)
          if [ $SIZE -gt 2000000000 ]; then
            # Split if > 2GB
            tar -czf - -C dist ai-image-tagger | split -b 2000m - "artifacts/${BASE_NAME}.tar.gz.part"
          else
            tar -czf "artifacts/${BASE_NAME}.tar.gz" -C dist ai-image-tagger
          fi

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: ${{ steps.platform.outputs.name }}-${{ matrix.config.name }}
          path: artifacts/
          retention-days: 5

  # Build Docker images for all configs
  build-docker:
    needs: setup
    strategy:
      fail-fast: false
      matrix:
        config: ${{ fromJson(needs.setup.outputs.configs) }}

    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write

    steps:
      - uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Determine CUDA base version
        id: cuda_base
        run: |
          CUDA_DISPLAY="${{ matrix.config.cuda_display }}"
          # Map CUDA display version to available NVIDIA base image tags
          # See: https://hub.docker.com/r/nvidia/cuda/tags
          # CUDA 12.1 uses -cudnn8-, CUDA 12.8 uses -cudnn-
          case "$CUDA_DISPLAY" in
            12.1)
              echo "version=12.1.1" >> $GITHUB_OUTPUT
              echo "cudnn_suffix=cudnn8" >> $GITHUB_OUTPUT
              ;;
            12.8)
              echo "version=12.6.2" >> $GITHUB_OUTPUT
              echo "cudnn_suffix=cudnn" >> $GITHUB_OUTPUT
              ;;
            *)
              echo "version=12.1.1" >> $GITHUB_OUTPUT
              echo "cudnn_suffix=cudnn8" >> $GITHUB_OUTPUT
              ;;
          esac

      - name: Extract metadata for Docker
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ghcr.io/${{ github.repository }}
          tags: |
            type=raw,value=${{ needs.setup.outputs.release_version }}-${{ matrix.config.name }}
            type=raw,value=py${{ matrix.config.python }}-cuda${{ matrix.config.cuda_display }}
            type=raw,value=latest-${{ matrix.config.name }},enable=${{ github.ref == format('refs/heads/{0}', github.event.repository.default_branch) }}

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          build-args: |
            PYTHON_VERSION=${{ matrix.config.python }}
            CUDA_VERSION=${{ matrix.config.cuda }}
            CUDA_BASE_VERSION=${{ steps.cuda_base.outputs.version }}
            CUDNN_SUFFIX=${{ steps.cuda_base.outputs.cudnn_suffix }}
          cache-from: type=gha,scope=${{ matrix.config.name }}
          cache-to: type=gha,mode=max,scope=${{ matrix.config.name }}
          platforms: linux/amd64

  # Create GitHub release with all artifacts
  create-release:
    needs: [setup, build-executables, build-docker]
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts
          merge-multiple: true

      - name: Prepare release artifacts
        run: |
          mkdir -p release-files
          # Copy all archive files (including split parts: .zip, .zip.001, .tar.gz, .partaa, etc.)
          find artifacts -type f \( -name "*.zip*" -o -name "*.tar.gz*" -o -name "*.part*" \) -exec cp {} release-files/ \;
          echo "Release files:"
          ls -lh release-files/

      - name: Generate release notes
        id: notes
        run: |
          cat > release-notes.md << 'EOF'
          ## ðŸŽ‰ AI Image Tagger ${{ needs.setup.outputs.release_version }}

          ### ðŸ“¦ Downloads

          Choose the build that matches your system:

          **Windows:**
          - `ai-image-tagger-windows-python310-cuda121.zip` - RTX 20/30/40 series (CUDA 12.1+)
          - `ai-image-tagger-windows-python312-cuda128.zip` - RTX 50 series (CUDA 12.8+)

          **Linux:**
          - `ai-image-tagger-linux-python310-cuda121.tar.gz` - RTX 20/30/40 series (CUDA 12.1+)
          - `ai-image-tagger-linux-python312-cuda128.tar.gz` - RTX 50 series (CUDA 12.8+)

          **Docker:**
          ```bash
          # RTX 20/30/40 series (most users)
          docker pull ghcr.io/${{ github.repository }}:${{ needs.setup.outputs.release_version }}-python310-cuda121

          # RTX 50 series
          docker pull ghcr.io/${{ github.repository }}:${{ needs.setup.outputs.release_version }}-python312-cuda128

          # Or use short tags
          docker pull ghcr.io/${{ github.repository }}:py3.10-cuda12.1
          docker pull ghcr.io/${{ github.repository }}:py3.12-cuda12.8
          ```

          ### ðŸš€ Quick Start

          **Windows:**
          1. Download the appropriate `.zip` file for your CUDA version
             - If split archives (`.zip.001`, `.zip.002`): Download ALL parts to same folder
          2. Extract:
             - Single file: Right-click â†’ Extract All
             - Split archives: Right-click `.zip.001` â†’ Extract All (7-Zip auto-detects parts)
          3. Run `ai-image-tagger/ai-image-tagger.exe`
          4. Open `http://localhost:5000` in your browser

          **Linux:**
          1. Download the appropriate `.tar.gz` file for your CUDA version
             - If split archives (`.partaa`, `.partab`): Download ALL parts to same folder
          2. Extract:
             - Single file: `tar -xzf ai-image-tagger-linux-*.tar.gz`
             - Split archives: `cat ai-image-tagger-linux-*.part* | tar -xzf -`
          3. Run: `./ai-image-tagger/ai-image-tagger`
          4. Open `http://localhost:5000` in your browser

          **Docker:**
          ```bash
          # RTX 20/30/40 series
          docker run --gpus all -p 5000:5000 ghcr.io/${{ github.repository }}:${{ needs.setup.outputs.release_version }}-python310-cuda121

          # RTX 50 series
          docker run --gpus all -p 5000:5000 ghcr.io/${{ github.repository }}:${{ needs.setup.outputs.release_version }}-python312-cuda128
          ```
          Open `http://localhost:5000` in your browser

          ### ðŸ“‹ Requirements

          - NVIDIA GPU with appropriate CUDA drivers
          - 4GB+ VRAM (8GB+ recommended for R-4B model)

          Models (~500MB-2GB) download automatically on first use.

          ### ðŸ’¡ Which Version to Download?

          **Check your GPU model:**
          ```bash
          nvidia-smi  # Look at GPU name
          ```

          **GPU Series Guide:**
          - RTX 2060/2070/2080, RTX 3060/3070/3080/3090, RTX 4060/4070/4080/4090 â†’ Use `cuda121` builds
          - RTX 5060/5070/5080/5090 (50 series) â†’ Use `cuda128` builds

          **By CUDA Driver Version:**
          - CUDA 12.1-12.7 drivers â†’ Use `cuda121` builds (compatible with RTX 20/30/40)
          - CUDA 12.8+ drivers â†’ Use `cuda128` builds (required for RTX 50)
          EOF

      - name: Create Release
        uses: softprops/action-gh-release@v2
        with:
          tag_name: ${{ needs.setup.outputs.release_version }}
          name: Release ${{ needs.setup.outputs.release_version }}
          body_path: release-notes.md
          draft: false
          files: release-files/*
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
