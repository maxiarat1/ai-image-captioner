name: Release

on:
  push:
    tags:
      - 'v*.*.*'
  workflow_dispatch:
    inputs:
      version:
        description: 'Version (e.g., v1.0.0)'
        required: true
        type: string

jobs:
  # Read version configuration and prepare matrix
  setup:
    runs-on: ubuntu-latest
    outputs:
      release_version: ${{ steps.version.outputs.release_version }}
      configs: ${{ steps.configs.outputs.matrix }}
    steps:
      - uses: actions/checkout@v4

      - name: Get release version
        id: version
        run: |
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            echo "release_version=${{ github.event.inputs.version }}" >> $GITHUB_OUTPUT
          else
            echo "release_version=${GITHUB_REF#refs/tags/}" >> $GITHUB_OUTPUT
          fi

      - name: Generate build matrix from version.json
        id: configs
        run: |
          # Extract all build configs and create matrix
          CONFIGS=$(jq -c '[.build_configs | to_entries[] | {
            name: .key,
            python: .value.python,
            cuda: .value.cuda,
            cuda_display: .value.cuda_version_display
          }]' version.json)
          echo "matrix=${CONFIGS}" >> $GITHUB_OUTPUT
          echo "Building configs:"
          echo "$CONFIGS" | jq -r '.[] | "  - \(.name): Python \(.python), CUDA \(.cuda_display)"'

  # Build executables for all configs and platforms
  build-executables:
    needs: setup
    strategy:
      fail-fast: false
      max-parallel: 2  # Limit parallel builds to avoid disk space issues
      matrix:
        os: [ubuntu-latest, windows-latest]
        config: ${{ fromJson(needs.setup.outputs.configs) }}

    runs-on: ${{ matrix.os }}

    steps:
      - uses: actions/checkout@v4

      - name: Free up disk space (Linux)
        if: runner.os == 'Linux'
        run: |
          echo "Disk space before cleanup:"
          df -h
          # Remove unnecessary tools to free up space (~30GB)
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /opt/ghc
          sudo rm -rf /usr/local/share/boost
          sudo rm -rf "$AGENT_TOOLSDIRECTORY"
          sudo rm -rf /usr/local/lib/android
          sudo rm -rf /usr/share/swift
          sudo rm -rf /opt/hostedtoolcache
          sudo docker system prune -af || true
          echo "Disk space after cleanup:"
          df -h

      - name: Free up disk space (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          echo "Disk space before cleanup:"
          Get-PSDrive
          # Remove unnecessary tools to free up space
          Remove-Item -Path "C:\hostedtoolcache" -Recurse -Force -ErrorAction SilentlyContinue
          Remove-Item -Path "C:\Program Files\dotnet" -Recurse -Force -ErrorAction SilentlyContinue
          echo "Disk space after cleanup:"
          Get-PSDrive

      - name: Set platform name
        id: platform
        shell: bash
        run: |
          if [ "${{ matrix.os }}" == "ubuntu-latest" ]; then
            echo "name=linux" >> $GITHUB_OUTPUT
            echo "ext=tar.gz" >> $GITHUB_OUTPUT
          else
            echo "name=windows" >> $GITHUB_OUTPUT
            echo "ext=zip" >> $GITHUB_OUTPUT
          fi

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.config.python }}

      - name: Install dependencies
        shell: bash
        run: |
          python -m pip install --upgrade pip
          pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/${{ matrix.config.cuda }}
          pip install -r requirements.txt
          pip install pyinstaller

      - name: Build executable
        shell: bash
        run: |
          cd backend
          pyinstaller captioner.spec --distpath ../dist --workpath ../build

      - name: Clean up build artifacts
        shell: bash
        run: |
          # Remove build cache to save space
          rm -rf build/
          # Clean pip cache
          pip cache purge || true

      - name: Package (Windows)
        if: steps.platform.outputs.name == 'windows'
        shell: bash
        run: |
          BASE_NAME="ai-image-captioner-${{ steps.platform.outputs.name }}-${{ matrix.config.name }}"
          mkdir -p artifacts
          # Create split archives if size > 2GB, otherwise single archive
          7z a -tzip -v2000m "${BASE_NAME}.zip" ./dist/ai-image-captioner
          # Move all parts to artifacts folder
          mv ${BASE_NAME}.zip* artifacts/

      - name: Package (Linux)
        if: steps.platform.outputs.name == 'linux'
        run: |
          BASE_NAME="ai-image-captioner-${{ steps.platform.outputs.name }}-${{ matrix.config.name }}"
          mkdir -p artifacts
          # Check size first
          SIZE=$(du -sb dist/ai-image-captioner | cut -f1)
          if [ $SIZE -gt 2000000000 ]; then
            # Split if > 2GB
            tar -czf - -C dist ai-image-captioner | split -b 2000m - "artifacts/${BASE_NAME}.tar.gz.part"
          else
            tar -czf "artifacts/${BASE_NAME}.tar.gz" -C dist ai-image-captioner
          fi

      - name: Final cleanup before upload
        shell: bash
        run: |
          # Remove dist folder after packaging to save space
          rm -rf dist/
          echo "Disk space before upload:"
          df -h || Get-PSDrive

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: ${{ steps.platform.outputs.name }}-${{ matrix.config.name }}
          path: artifacts/
          retention-days: 5

  # Build Docker images for all configs
  build-docker:
    needs: setup
    strategy:
      fail-fast: false
      matrix:
        config: ${{ fromJson(needs.setup.outputs.configs) }}

    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write

    steps:
      - uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Determine CUDA base version
        id: cuda_base
        run: |
          CUDA_DISPLAY="${{ matrix.config.cuda_display }}"
          # Map CUDA display version to available NVIDIA base image tags
          # See: https://hub.docker.com/r/nvidia/cuda/tags
          # CUDA 12.1 uses -cudnn8-, CUDA 12.8 uses -cudnn-
          case "$CUDA_DISPLAY" in
            12.1)
              echo "version=12.1.1" >> $GITHUB_OUTPUT
              echo "cudnn_suffix=cudnn8" >> $GITHUB_OUTPUT
              ;;
            12.8)
              echo "version=12.6.2" >> $GITHUB_OUTPUT
              echo "cudnn_suffix=cudnn" >> $GITHUB_OUTPUT
              ;;
            *)
              echo "version=12.1.1" >> $GITHUB_OUTPUT
              echo "cudnn_suffix=cudnn8" >> $GITHUB_OUTPUT
              ;;
          esac

      - name: Extract metadata for Docker
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ghcr.io/${{ github.repository }}
          tags: |
            type=raw,value=${{ needs.setup.outputs.release_version }}-${{ matrix.config.name }}
            type=raw,value=latest-${{ matrix.config.name }}

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          build-args: |
            PYTHON_VERSION=${{ matrix.config.python }}
            CUDA_VERSION=${{ matrix.config.cuda }}
            CUDA_BASE_VERSION=${{ steps.cuda_base.outputs.version }}
            CUDNN_SUFFIX=${{ steps.cuda_base.outputs.cudnn_suffix }}
          cache-from: type=gha,scope=${{ matrix.config.name }}
          cache-to: type=gha,mode=max,scope=${{ matrix.config.name }}
          platforms: linux/amd64

  # Create GitHub release with all artifacts
  create-release:
    needs: [setup, build-executables, build-docker]
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - uses: actions/checkout@v4

      - name: Free up disk space
        run: |
          echo "Disk space before cleanup:"
          df -h
          # Remove unnecessary tools to free up space for 12GB of artifacts
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /opt/ghc
          sudo rm -rf /usr/local/share/boost
          sudo rm -rf /usr/local/lib/android
          sudo rm -rf /usr/share/swift
          sudo rm -rf /opt/hostedtoolcache
          sudo docker system prune -af || true
          echo "Disk space after cleanup:"
          df -h

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts

      - name: Prepare release artifacts
        run: |
          mkdir -p release-files
          # Copy all archive files (including split parts: .zip, .zip.001, .tar.gz, .partaa, etc.)
          find artifacts -type f \( -name "*.zip*" -o -name "*.tar.gz*" -o -name "*.part*" \) -exec cp {} release-files/ \;
          # Remove artifacts folder to save space
          rm -rf artifacts/
          echo "Release files:"
          ls -lh release-files/
          echo "Disk space after prep:"
          df -h

      - name: Generate release notes
        id: notes
        run: |
          cat > release-notes.md << 'EOF'
          ## AI Image Captioner ${{ needs.setup.outputs.release_version }}

          ### Quick Start

          **Option 1: Executable (Recommended)**

          1. Download the appropriate file for your GPU:
             - **Windows RTX 20/30/40:** `ai-image-captioner-windows-python310-cuda121.zip`
             - **Windows RTX 50:** `ai-image-captioner-windows-python312-cuda128.zip`
             - **Linux RTX 20/30/40:** `ai-image-captioner-linux-python310-cuda121.tar.gz`
             - **Linux RTX 50:** `ai-image-captioner-linux-python312-cuda128.tar.gz`

          2. Extract and run:
             - **Windows:** Double-click `ai-image-captioner.exe` (extract with 7-Zip if split)
             - **Linux:** `tar -xzf ai-image-captioner-linux-*.tar.gz && ./ai-image-captioner/ai-image-captioner`

          3. API backend runs at `http://localhost:5000`

          **Option 2: Docker**

          ```bash
          # RTX 20/30/40 series
          docker run --gpus all -p 5000:5000 ghcr.io/${{ github.repository }}:${{ needs.setup.outputs.release_version }}-python310-cuda121

          # RTX 50 series
          docker run --gpus all -p 5000:5000 ghcr.io/${{ github.repository }}:${{ needs.setup.outputs.release_version }}-python312-cuda128
          ```

          API runs at `http://localhost:5000`

          **Frontend UI:**

          Clone the repository and serve the `frontend/` directory, or open `frontend/index.html` directly.

          ### Requirements

          - NVIDIA GPU with 4GB+ VRAM (8GB+ for AI models)
          - CUDA 12.1+ drivers (RTX 20/30/40) or CUDA 12.8+ (RTX 50)
          - Docker users: `nvidia-container-toolkit` (see README if you get GPU errors)

          (AI models are not baked in. They are downloaded on first run from the Hugging Face Hub.)
          EOF

      - name: Create Release
        uses: softprops/action-gh-release@v2
        with:
          tag_name: ${{ needs.setup.outputs.release_version }}
          name: Release ${{ needs.setup.outputs.release_version }}
          body_path: release-notes.md
          draft: false
          files: release-files/*
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
